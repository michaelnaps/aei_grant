\section{Breakdown}

\subsection{Rationale}

	The primary goal of Aim 3 will be to re-train the neural network developed by the 2022 computer science and engineering capstone team on real anatomical footage and integrate the network with the on-board micro-controller. Their system is currently trained to identify and trace the anatomical features of the airway from video records. The outputs of the identifier network are boxes which encapsulate the feature, as well as a confidence interval value which relays how likely it is that the feature was identified correctly. Currently the network is trained on mannequin airway data, and was used solely for demonstration purposes.

	The automation component of the device is wholly dependent on the system discussed here. It will most likely be implemented on board the device, but depending on its weight and run-time specifications, it may be run on a separate unit, with a slightly more complex wired communication system.
	
	Figure \ref{fig:cseproject_demo} shows a demonstration of the CSE team's newtork in progress. The results among all test were relatively similar, with some difficulty noticed as the camera approached the airway. That said, with more training the network should be able to overcome this issue. The footage referenced is currently held by the Wexner Medical Center and will be securely released to this project for the express purpose of training the network.
	
	\begin{figure}[ht]
		\centering
		\includegraphics[scale=0.85]{cseproject_demo}
		\caption{Anatomy Identification Network on Airway Mannequin Footage}
		\label{fig:cseproject_demo}
	\end{figure}

\subsection{Approach}

	\subsubsection{Timeline}
	
		During the 2022 Spring semester, the BME department at the OSU commisioned a CSE department capstone project with the intent to develop a functional AI system. This network can be used to identify the anatomical features of the human mouth and airway. For the purpose of the project, the network was limited to identification of features on a mannequin. That said, the network developed was capable of identifying the uvula, epiglottis and vocal chords as shown in Figure \ref{fig:cseproject_demo}.
		
		To expand off of this project, three main tasks will be completed. First, the network will be retrained on the real-anatomy data set already collected by the Wexner Medical Center. This process will most likely be given about $40\%$ of the total project time, i.e. $5[months]$ in a year-long project, and are stated in lines $47-52$ of Figure \ref{fig:full_timeline}.
		
		The network will then be integrated with the main controller hardware. This will most likely involve a communication system between the external network, the controller being programmed for Aim 1 and the camera system. It is currently unclear how exactly this will be implemented, but time will be set aside specifically to problem solve this requirement. This process will also be given approximately $40\%$ of the total project time. It should be noted that Specific Aim 1 need not be completed for this process to be tested. As long as it can be proven that the hardware is able to read and utilize the output of the controller (even if that is simply outputting results to the screen), the test will be considered complete (lines $53-58$ of Figure \ref{fig:full_timeline}).
		
		The final test will consist of verifying that the identification software can be utilized in real time using the on-board camera. These tests will likely require the use of the mannequin, but will eventually be demonstrated on cadaver subjects as well (although the cadaver tests are unlikely to occur in this time frame). Again, these tests have no dependency on Aim 1 or 2 since the only system being verified is the identification system. This portion of the project will be given the remaining $20\%$ of the project timeline (around $2[months]$). Shown in lines $59-62$ of the Full Project Timeline.

		The completed timeline, as well as those constructed for Aim 1 and 2, is shown in Figure \ref{fig:full_timeline}.
		
	\subsubsection{Network Testing and Integration}
	
		The neural network referenced here is largely sitting in a completed state. It is currently trained on a set of human mannequin example videos and performs to a high degree of accuracy. Once access is granted for the human intubation procedure videos housed on the Ohio State University Wexner Medical Center computer system, the network can be re-trained on real human anatomy data. The work done by the CSE department capstone team will be used to streamline this process as the neural network layers were setup in a reusable manner.

		Once the network is trained, a communication system between the on-board micro-controller and the NN will be developed. The current plan is to evaluate the run-time needs of the neural network and quantify whether it can be run from within the housing module, or if it should be run externally and communicate via a wired connection. It should be noted that the control system from Aim 1 does not need to be finished to test this communication system. As long as the outputs from the network match the inputs to the controller, they can be developed in parallel. This means that at the beginning of both processes, the communication point will be defined thoroughly to alleviate any difficulties down the road, this task will likely be completed during the Environment Setup period.
	
	\subsubsection{Experimental Process}
	
		The testing of the NN will initially be repeated over the set of mannequin video data as a way of checking that the environment is setup properly. Once the environment is verified, and access is granted for the intubation procedure data, the NN will be retrained. Testing will occur in parallel to the network tuning, somewhat similar to the process described in Section \ref{sect:aim1_experimental_process}. The precise criteria for suitable confidence levels, etc. will be better described at the beginning of this process and with considerable research on other self-guiding systems, of which there are many in other safety-oriented fields.
		
		As for the communication portion of the aim, the tests performed will be less subjective. The primary goal here will be to verify that the AI is able to publish feature locations to the main controller at an acceptable rate. The following time period will consist of real-time mannequin tests, as well as various cadaver tests which currently fall outside the scope of this project timeline.

\subsection{Risks and Alternatives}

	The largest risk for the development of the neural network is defining the level of confidence which the controller will allow before deciding a motion is safe. In other words, how low of a confidence is acceptable before the controller refuses to move in that direction. Setting this value too low factors in an obvious level of risk to the patient, as the device may navigate towards incorrectly identified features. Setting this setting too high may put the device at risk of stalling, i.e. reaching a point where no features are identifiable and not being able to make a decision. Ideally, a fail-safe will be implemented to account for this but it is also important to remember that the device as a whole is being designed with the intent that the practitioner is never absent from the procedure. They are required to watch the approach of the robot into the airway, and in these rare instances they would easily be able to manually override the neural network and move the robot in the proper direction.